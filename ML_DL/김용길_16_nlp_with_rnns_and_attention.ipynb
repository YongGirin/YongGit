{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1607995951973,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "9zgKH5P967tN",
    "outputId": "dfaf4390-6fde-47a0-c2c0-2abfd4449008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n",
      "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "\n",
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "\n",
    "import sklearn\n",
    "\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "# %tensorflow_version only exists in Colab.\n",
    "\n",
    "  %tensorflow_version 2.x\n",
    "\n",
    "  !pip install -q -U tensorflow-addons\n",
    "\n",
    "  IS_COLAB = True\n",
    "\n",
    "except Exception:\n",
    "\n",
    "  IS_COLAB = False\n",
    "\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "\n",
    "  print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "\n",
    "  if IS_COLAB:\n",
    "\n",
    "    print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "\n",
    "# Common imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# Where to save the figures\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "CHAPTER_ID = \"nlp\"\n",
    "\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "\n",
    "  path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "\n",
    "  print(\"Saving figure\", fig_id)\n",
    "\n",
    "  if tight_layout:\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "  plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3390,
     "status": "ok",
     "timestamp": 1607995951975,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "quU4f7uo9PFp",
    "outputId": "3af5c321-e196-4429-93da-454227cc0259"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./images/nlp'"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3378,
     "status": "ok",
     "timestamp": 1607995951977,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "w4aubNye9WT4",
    "outputId": "203ad63f-6aea-4da3-9936-726c87e251a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Batch 0 \n",
      "X_batch\n",
      "[[6 7 8 9]\n",
      " [2 3 4 5]\n",
      " [4 5 6 7]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 7  8  9 10]\n",
      " [ 3  4  5  6]\n",
      " [ 5  6  7  8]]\n",
      "-------------------- Batch 1 \n",
      "X_batch\n",
      "[[ 0  1  2  3]\n",
      " [ 8  9 10 11]\n",
      " [10 11 12 13]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 1  2  3  4]\n",
      " [ 9 10 11 12]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_steps=5\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
    "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window:window.batch(n_steps))\n",
    "dataset = dataset.shuffle(10).map(lambda window: (window[:-1],window[1:]))\n",
    "dataset = dataset.batch(3).prefetch(1)\n",
    "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
    "  print(\"-\"*20, \"Batch\", index, \"\\nX_batch\")\n",
    "  print(X_batch.numpy())\n",
    "  print(\"=\"*5, \"\\nY_batch\")\n",
    "  print(Y_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f2l2fPj-tiR"
   },
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXzVz6BS-ujW"
   },
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "  shakespeare_text = f.read(\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3353,
     "status": "ok",
     "timestamp": 1607995951980,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "maYMCvBWA7Uy",
    "outputId": "bf6aa060-ce77-495b-ddd2-9cc1f87e7464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3340,
     "status": "ok",
     "timestamp": 1607995951981,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "nVAxTUKYBP7Y",
    "outputId": "121558cc-0731-4b3b-d75d-3f66f6a33627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(type(shakespeare_text))\n",
    "print(len(shakespeare_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3748,
     "status": "ok",
     "timestamp": 1607995952402,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "IPEwUA36BTZT",
    "outputId": "2793e00d-3774-431e-ddca-0a7e4516d552"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZe7ry4TB63j"
   },
   "source": [
    "모든 글자를 정수로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmdbGuiICMC-"
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "# char_level : 단어 수준 인코딩 대신 글자 수준 인코딩\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4709,
     "status": "ok",
     "timestamp": 1607995953385,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "_T9l2Bq4CfGf",
    "outputId": "7c8ed195-6f1c-4a49-fb02-275e48c5d957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4696,
     "status": "ok",
     "timestamp": 1607995953386,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "4We4hN33Cptw",
    "outputId": "bfaf10bc-044c-44ed-c230-6ec745813f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20,6,9,8,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4683,
     "status": "ok",
     "timestamp": 1607995953387,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "BhlnEMSmCvAF",
    "outputId": "82ea2628-339f-450b-c613-355d6d18d973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([20,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4671,
     "status": "ok",
     "timestamp": 1607995953389,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "ohTdMO70C4l-",
    "outputId": "3cb91fc8-7f6b-432c-f3f9-5ae861639f94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([[20,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4657,
     "status": "ok",
     "timestamp": 1607995953390,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "07pyiOEuC6GK",
    "outputId": "8d283fde-24f5-4603-b8c2-de7300b3fac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index) # 고유 글자 개수\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4643,
     "status": "ok",
     "timestamp": 1607995953392,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "jivgtByrDG7G",
    "outputId": "6425519a-3572-4d87-be5d-055c6e9e5c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count # 전체 글자 개수\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewdWnckADO2A"
   },
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text]))-1 # 1~39 -> 0~ 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1ogdXmWEQcv"
   },
   "source": [
    "훈련, 검증, 테스트로 나누어아하지만 순서를 텍스트에 있는 글자를 섞으면 안됨\n",
    "\n",
    "-> \n",
    "\n",
    "처음에 등장한 로직 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV-XiDD1E-jS"
   },
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "# 텍스트의 처음 90%를 트레인 셋으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iV5o43-AFOyb"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4942,
     "status": "ok",
     "timestamp": 1607995953727,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "DjjORYDOFPzz",
    "outputId": "afa2002a-46ca-4b61-fc01-bfbca53269fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTTZCem7clh_"
   },
   "source": [
    "window() 메서드로 짧은 텍스트 윈도를 갖는 데이터셋 생성\n",
    "\n",
    "RNN은 이 부분 문자열 길이만큼만 역전파를 위해 펼쳐짐 -> Truncated BackPropagation Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXqcxirHc7AQ"
   },
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = 1글자 앞의 input\n",
    "dataset = dataset.repeat().window(window_length, shift = 1, \n",
    "                         drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgYLDQAWee0f"
   },
   "source": [
    "첫번째 윈도우는 0~100 번째 글자 포함\n",
    "\n",
    "두번째 윈도우는 1~101 번째 글자 포함\n",
    "\n",
    "drop_remainder = True 로 해놓으면 모든 윈도우가 동일하게 101개의 글자를 포함\n",
    "\n",
    "False로 지정하면 100개, 99개, 98개 , ... , 식으로 점점 줄어 마지막 윈도우는 글자 1개만 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSp7w7juf3-5"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8GrjR2IhOFW"
   },
   "source": [
    "window() 메서드는 각각 하나의 데이터셋으로 표현되는 윈도우를 포함하는 데이터 셋을 만듬 -> 리스트의 리스트와 비슷한 ***중첩 데이터셋***\n",
    "\n",
    "하지만 모델은 데이터셋이 아니라 ***텐서***를 기대하기 때문에 중첩 데이터셋을 ***플랫 데이터셋***으로 변환하는 flat_map() 메서드를 호출해야함\n",
    "\n",
    "ex) {{1,2}, {3,4,5,6}} -> flat_map() -> {1,2,3,4,5,6}\n",
    "\n",
    "ex) lambda ds: ds.batch(2) 함수를 flat_map()에 전달 -> {{1,2},{3,4,5,6}} -> {{1,2},{3,4},{5,6}} 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cobnvrbfxpT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuLN5y34eebP"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(1000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:,:-1], windows[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9K-SwOt5i1hG"
   },
   "source": [
    "윈도우를 배치로 만들고 -> ```dataset.shuffle(1000).batch(batch_size)```\n",
    "\n",
    "입력(처음 100개의 글자) 와 타깃(마지막 글자) 분리 -> ```dataset.map(lambda windows: (windows[:,:-1], windows[:,1:]))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j92XSdx5fZLI"
   },
   "outputs": [],
   "source": [
    "딩dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-ktmIgmjgjD"
   },
   "source": [
    "원-핫 벡터를 사용해 글자 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdwrCyJ4jfPn"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5175,
     "status": "ok",
     "timestamp": 1607995954017,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "v6tgu8I5j_tT",
    "outputId": "47f2d33d-e72b-49c2-ef1d-d8527ade3348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "  print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAOs5-BlkHLh"
   },
   "source": [
    "## Char-RNN 모델 만들고 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4ROqygukY2-"
   },
   "source": [
    "이전 글자 100개를 기반해 다음 글자를 예측하기 위해 유닛 128개를 가진 GRU 층 2개, 입력과 은닉에 20% 드롭아웃 사용\n",
    "(하이퍼 파라미터 수정 가능)\n",
    "\n",
    "출력층은 TimeDistributed 클래스를 적용한 Dense 층\n",
    "\n",
    "텍스트의 고유한 글자 수는 39개 이므로 이 층은 39개의 유닛(max_id)를 가져야 함\n",
    "\n",
    "출력 확률의 합은 1이어야 하므로 Dense 층의 출력은 소프트맥스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "executionInfo": {
     "elapsed": 74931,
     "status": "error",
     "timestamp": 1607996023787,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "v1JM4Zgvk7lP",
    "outputId": "fe705db2-8174-4dfd-834b-9b05865eb436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  147/31370 [..............................] - ETA: 3:45:40 - loss: 2.8027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-957108f61440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m               optimizer = \"adam\")\n\u001b[1;32m     13\u001b[0m history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n\u001b[0;32m---> 14\u001b[0;31m                     epochs=10)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# 시간 굉장히 오래걸림\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.GRU(128, return_sequences=True, input_shape=[None,max_id],\n",
    "                   dropout=0.2, recurrent_dropout=0.2),\n",
    "  \n",
    "  keras.layers.GRU(128, return_sequences=True,\n",
    "                   dropout=0.2, recurrent_dropout=0.2),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                  activation=\"softmax\"))                                 \n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"adam\")\n",
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=10)\n",
    "# 시간 굉장히 오래걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-hQ1v3olqQ-"
   },
   "source": [
    "## 상태가 있는 RNN\n",
    "- RNN이 한 훈련 배치를 처리한 후에 마지막 상태를 다음 훈련 배치의 초기 상태로 사용\n",
    "- 역전파는 짧은 시퀀스에서 일어나지만 모델이 장기간 패턴을 학습할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJLqUmUun7g1"
   },
   "source": [
    "dataset을 만들 때 window() 메서드에서 shift = 1 대신에 shift = n_steps를 사용하여 순차적이고 겹치지 않는 입력 시퀀스 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW_0c091qgZH"
   },
   "source": [
    "## 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zvRKxGHqiVg"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AanaBqY9qqB8"
   },
   "outputs": [],
   "source": [
    "(X_train, y_test),(X_valid, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7086,
     "status": "ok",
     "timestamp": 1607996037861,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "y_ZQDbyCq3e-",
    "outputId": "b8de663f-f230-43dd-ad7a-3559e37a423c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "print(X_train[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgPuTGelq5ip"
   },
   "source": [
    "디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7078,
     "status": "ok",
     "timestamp": 1607996037863,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "NXUrz-WNrNsh",
    "outputId": "b21a34e2-75a3-4f92-b51d-e66d3f5a10db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_+3: word for word, id_ in word_index.items()}\n",
    "for id_, token in enumerate((\"<pad>\",\"<sos>\",\"<unk>\")):\n",
    "  id_to_word[id_] = token\n",
    "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 7069,
     "status": "ok",
     "timestamp": 1607996037864,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "7pF21Nkirus5",
    "outputId": "5f734407-81a0-4a20-bb99-cc79b489ba40"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<sos> big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs\""
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([id_to_word[id_] for id_ in X_train[1][:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7061,
     "status": "ok",
     "timestamp": 1607996037866,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "U5fyJnSus2nA",
    "outputId": "cc6a3c8e-0a89-4c5f-ca92-1428929114b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7055,
     "status": "ok",
     "timestamp": 1607996037870,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "sxXB7eAEySxd",
    "outputId": "f1d4ae75-a840-4cf1-bf6a-4c4b654a84dc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'film'"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_4AR8zuy15f"
   },
   "source": [
    "### 전처리 함수작성\n",
    "+ 현실에서는 항상 전처리 과정을 거쳐야함\n",
    "+ 전처리를 모델 자체에 포함시키는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfP9gLe21I3Y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86HqmbiD2iEY"
   },
   "source": [
    "텐서플로 데이터셋의 원본 IMDb리뷰를 텍스트(바이트스트링) 으로 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7040,
     "status": "ok",
     "timestamp": 1607996037874,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "Abgl8t7G4THN",
    "outputId": "eb2ec265-0ff5-4141-f95a-5e0746049c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    version=1.0.0,\n",
       "    description='Large Movie Review Dataset.\n",
       "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'text': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    total_num_examples=100000,\n",
       "    splits={\n",
       "        'test': 25000,\n",
       "        'train': 25000,\n",
       "        'unsupervised': 50000,\n",
       "    },\n",
       "    supervised_keys=('text', 'label'),\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7031,
     "status": "ok",
     "timestamp": 1607996037875,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "9xjv5GqI2N_U",
    "outputId": "3fc3d4bf-3734-4962-93b1-853f642c255c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'unsupervised'])"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7026,
     "status": "ok",
     "timestamp": 1607996037880,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "ZDZT-e2H4kKu",
    "outputId": "8f459400-7492-4a7a-e8cc-092458243e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mn9WzLx2UNn"
   },
   "outputs": [],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7408,
     "status": "ok",
     "timestamp": 1607996038285,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "aGayqfMd678J",
    "outputId": "96f993b1-2732-4e49-aeaf-01756948e44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).take(1):\n",
    "\n",
    "  for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "\n",
    "    print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "\n",
    "    print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7399,
     "status": "ok",
     "timestamp": 1607996038286,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "Sp-6PnIB-h0R",
    "outputId": "b501d6ef-5f23-4c5f-ed62-38cf9e4056be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
       "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3sT0GIZ8nPa"
   },
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "  X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "  X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
    "  X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "  X_batch = tf.strings.split(X_batch)\n",
    "  return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHfyIdhe-VNw"
   },
   "source": [
    "- 훈련 속도를 높이기 위해 각 리뷰에서 처음 300 글자만 남김\n",
    "- <br /> 태그를 공백으로 바굼\n",
    "- 문자와 작은 따옴표가 아닌 다른 모든 문자를 공백으로 바꿈\n",
    "- ``` X_batch = tf.strings.split(X_batch) ``` 로 리뷰를 공백으로 나눔\n",
    "- 이떄 ragged tensor 반환\n",
    "- 이 텐서를 밀집 텐서로 바꾸고 동일한 길이가 되도록 패딩 토큰 pad 로 모든 리뷰를 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1607996075444,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "5K0Ec_nH-XTr",
    "outputId": "5b53e1cb-214c-4df8-819a-95d73d43a911"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 53), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Cons']], dtype=object)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0])>)"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KelLoeHU9jqh"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "  for review in X_batch:\n",
    "    vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdSCZBzNGskD"
   },
   "source": [
    "어휘사전 구축\n",
    "+ 전체 훈련셋을 한 번 순회하면서 preprocess 함수를 적용\n",
    "+ Counter 로 단어의 등장 횟수를 셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1607997320707,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "ozJPzJuxG6yg",
    "outputId": "fe6df597-a287-42d2-f9e4-7a2b289a67d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1607997330106,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "Hi1jYgoqG-vI",
    "outputId": "0adfe666-3f11-4bde-8fd6-7c62409bbe7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1607998031421,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "5hpd7lXMHBAZ"
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "  word for word, count in vocabulary.most_common()[:vocab_size]                           \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1607998032783,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "LuM4StOFHi2D",
    "outputId": "d4615fea-4d19-4dc3-e72f-0819100dd9f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and', b'to', b'I', b'is', b'in', b'this']"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1607998033780,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "kGOpTtfZHkvm",
    "outputId": "8e82f6c7-c689-4bf1-b056-9d70e66af0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "12\n",
      "11\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word : index for index, word in enumerate(truncated_vocabulbary)}\n",
    "for word in b\"This movie was faaaaaantastic\".split():\n",
    "  print(word_to_id.get(word) or vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1607998048139,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "7JKCDncJItVA"
   },
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulbary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1607998083771,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "vWP_qgkXI4uO",
    "outputId": "69f1b608-6bec-4cb7-93c4-24c255037446"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10791]])>"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wNvQGMDJ7EE"
   },
   "source": [
    "각 단어에 ID 부여\n",
    "\n",
    "1000개의 oov(out of vocabulary) 버킷을 사용하는 룩업 테이블을 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1607998295744,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "eY8yUBk7J4-H"
   },
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "  return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = datasets[\"train\"].repeat().batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1607998340486,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "PHvKYSqaKqfM",
    "outputId": "fc30e3e8-1a66-43e7-8923-2ef8e64bce32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  22   11   28 ...    0    0    0]\n",
      " [   6   21   70 ...    0    0    0]\n",
      " [4099 6881    1 ...    0    0    0]\n",
      " ...\n",
      " [  22   12  118 ...  331 1047    0]\n",
      " [1757 4101  451 ...    0    0    0]\n",
      " [3365 4392    6 ...    0    0    0]], shape=(32, 60), dtype=int64)\n",
      "tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_set.take(1):\n",
    "  print(X_batch)\n",
    "  print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626117,
     "status": "ok",
     "timestamp": 1607999390312,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "Pmvh83RhKyXt",
    "outputId": "356d44b3-7641-4f85-ca05-2169058a4229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "781/781 [==============================] - 120s 154ms/step - loss: 0.5340 - accuracy: 0.7244\n",
      "Epoch 2/5\n",
      "781/781 [==============================] - 125s 159ms/step - loss: 0.3503 - accuracy: 0.8563\n",
      "Epoch 3/5\n",
      "781/781 [==============================] - 125s 160ms/step - loss: 0.1891 - accuracy: 0.9325\n",
      "Epoch 4/5\n",
      "781/781 [==============================] - 124s 159ms/step - loss: 0.1407 - accuracy: 0.9491\n",
      "Epoch 5/5\n",
      "781/781 [==============================] - 123s 158ms/step - loss: 0.1118 - accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                         mask_zero=True,\n",
    "                         input_shape=[None]),\n",
    "  keras.layers.GRU(128, return_sequences=True),\n",
    "  keras.layers.GRU(128),\n",
    "  keras.layers.Dense(1, activation=\"sigmoid\")                                                        \n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, steps_per_epoch = train_size // 32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unHb6Y9WN-JT"
   },
   "source": [
    "- 첫 번째 층은 단어 ID를 임베딩으로 변환하는 Embedding 층\n",
    "- 임베딩 행렬은 단어 ID 당 vocab_size + num_oov_buckets) 하나의 행과 임베딩 차원(128, 하이퍼파라미터) 당 하나의 열을 가짐\n",
    "- 모델의 입력은 [배치크기, 타임스텝 수] 크기를 가진 2D 텐서 이지만 출력은 [배치 크기, 타임 스텝 수, 임베딩 크기] 의 크기를 가진 3D 텐서가 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 1688,
     "status": "ok",
     "timestamp": 1608005536628,
     "user": {
      "displayName": "김용길",
      "photoUrl": "",
      "userId": "00028506768877938944"
     },
     "user_tz": -540
    },
    "id": "VZsFwWjOMMOy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyN66PuG+2Glb7pKZwlquqqj",
   "collapsed_sections": [],
   "name": "김용길_16_nlp_with_rnns_and_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
